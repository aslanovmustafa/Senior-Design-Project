{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import regex\n",
    "\n",
    "class MarkovChain:\n",
    "    def __init__(self):\n",
    "         self.memory = {}\n",
    "\n",
    "    def _learn_key(self, *key, value):\n",
    "        if key not in self.memory:\n",
    "            self.memory[key] = []\n",
    "\n",
    "        self.memory[key].append(value)\n",
    "\n",
    "    \n",
    "    def train2(self, text):\n",
    "        \n",
    "        tokens = text.split(\" \")\n",
    "        bigrams = [(tokens[i], tokens[i + 1]) for i in range(0, len(tokens) - 1)]\n",
    "        bi_count = Counter(bigrams)\n",
    "        for bigram in bigrams:\n",
    "            self._learn_key(bigram[0], value = bigram[1])\n",
    "        return bi_count.most_common(30)\n",
    "    \n",
    "    def train3(self, text):\n",
    "        tokens = text.split(\" \")\n",
    "        trigrams = [(tokens[i], tokens[i + 1], tokens[i + 2]) for i in range(0, len(tokens) - 2)]\n",
    "        tri_count = Counter(trigrams)\n",
    "        # pprint(trigrams)\n",
    "        for trigram in trigrams:\n",
    "            self._learn_key(trigram[0], trigram[1], value = trigram[2])\n",
    "        return tri_count.most_common(30)\n",
    "    \n",
    "    def train4(self, text):\n",
    "        tokens = text.split(\" \")\n",
    "        quadgrams = [(tokens[i], tokens[i + 1], tokens[i + 2], tokens[i + 3]) for i in range(0, len(tokens) - 3)]\n",
    "        quad_count = Counter(quadgrams)\n",
    "        # pprint(quadgrams)\n",
    "        for quadgram in quadgrams:\n",
    "            self._learn_key(quadgram[0], quadgram[1], quadgram[2], value = quadgram[3])\n",
    "        return quad_count.most_common(30)\n",
    "    \n",
    "    def train5(self, text):\n",
    "        tokens = text.split(\" \")\n",
    "        fivegrams = [(tokens[i], tokens[i + 1], tokens[i + 2], tokens[i + 3], tokens[i + 4]) for i in range(0, len(tokens) - 4)]\n",
    "        five_count = Counter(fivegrams)\n",
    "        # pprint(fivegrams)\n",
    "        for fivegram in fivegrams:\n",
    "            self._learn_key(fivegram[0], fivegram[1], fivegram[2],fivegram[3], value = fivegram[4])\n",
    "        return five_count.most_common(30)\n",
    "    \n",
    "    def next(self, *current_state):\n",
    "        next_possible = self.memory.get(current_state)\n",
    "\n",
    "        if not next_possible:\n",
    "            next_possible = self.memory.keys()\n",
    "\n",
    "        cnt = Counter(next_possible) \n",
    "        \n",
    "        most_common = cnt.most_common(1)[0][0]\n",
    "        elements = list(cnt)\n",
    "        common_elements = cnt.most_common(10)\n",
    "        \n",
    "        return most_common, elements, common_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # lower case text\n",
    "    newString = text.lower()\n",
    "    # adding space in place of punctuation between two words e.g: \"...redaktə edilib.Bu\", so it can be split later.\n",
    "    newString = regex.sub((r\"(?<=\\w)(\\W)(?=\\w)\"), ' ', newString)\n",
    "    # remove punctuations\n",
    "    newString = regex.sub((r\"[^\\A\\p{L}+\\z ]\"), '', newString) # matches unicode characters \n",
    "    # remove short words x_X\n",
    "    long_words = []\n",
    "    for i in newString.split():\n",
    "        if len(i) >= 2:\n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip()\n",
    " \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"combined_corpus_2.5.csv\")\n",
    "text = data.to_string()\n",
    "\n",
    "# preprocess the text\n",
    "data_new = text_cleaner(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('cinsinə', 'aid'), 11150),\n",
       " (('aid', 'bitki'), 10370),\n",
       " (('bitki', 'növü'), 9984),\n",
       " (('fəsiləsinin', 'cinsinə'), 9944),\n",
       " (('növü', 'mənbə'), 7755),\n",
       " (('ölkələrinə', 'görə'), 7135),\n",
       " (('istinadlar', 'kateqoriya'), 6830),\n",
       " (('kateqoriya', 'ölkələrinə'), 5839),\n",
       " (('xarici', 'keçidlər'), 5719),\n",
       " (('mənbə', 'fəsiləsinin'), 5041),\n",
       " (('ci', 'ildə'), 3764),\n",
       " (('həmçinin', 'bax'), 3737),\n",
       " (('cı', 'il'), 3344),\n",
       " (('daxil', 'olan'), 2759),\n",
       " (('azərbaycan', 'ostanının'), 2610),\n",
       " (('əhalisi', 'cı'), 2593),\n",
       " (('kənd', 'əhalisi'), 2416),\n",
       " (('olan', 'kənd'), 2410),\n",
       " (('ərazisinə', 'daxil'), 2408),\n",
       " (('şəhristanı', 'ərazisinə'), 2395),\n",
       " (('kateqoriya', 'azərbaycan'), 2382),\n",
       " (('azərbaycan', 'respublikasının'), 2373),\n",
       " (('qərbi', 'azərbaycan'), 2352),\n",
       " (('məlumatına', 'görə'), 2336),\n",
       " (('görə', 'kənddə'), 2331),\n",
       " (('illərinə', 'görə'), 2314),\n",
       " (('il', 'məlumatına'), 2310),\n",
       " (('iranın', 'qərbi'), 2281),\n",
       " (('yaşayır', 'ailə'), 2269),\n",
       " (('nəfərkəndin', 'əhalisi'), 2261)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = MarkovChain()\n",
    "m2.train2(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('aid', 'bitki', 'növü'), 9963),\n",
       " (('fəsiləsinin', 'cinsinə', 'aid'), 9944),\n",
       " (('cinsinə', 'aid', 'bitki'), 9936),\n",
       " (('bitki', 'növü', 'mənbə'), 6907),\n",
       " (('kateqoriya', 'ölkələrinə', 'görə'), 5775),\n",
       " (('mənbə', 'fəsiləsinin', 'cinsinə'), 5041),\n",
       " (('növü', 'mənbə', 'fəsiləsinin'), 4897),\n",
       " (('ərazisinə', 'daxil', 'olan'), 2406),\n",
       " (('daxil', 'olan', 'kənd'), 2402),\n",
       " (('şəhristanı', 'ərazisinə', 'daxil'), 2395),\n",
       " (('olan', 'kənd', 'əhalisi'), 2344),\n",
       " (('qərbi', 'azərbaycan', 'ostanının'), 2326),\n",
       " (('əhalisi', 'cı', 'il'), 2313),\n",
       " (('il', 'məlumatına', 'görə'), 2309),\n",
       " (('kənd', 'əhalisi', 'cı'), 2306),\n",
       " (('cı', 'il', 'məlumatına'), 2297),\n",
       " (('məlumatına', 'görə', 'kənddə'), 2295),\n",
       " (('iranın', 'qərbi', 'azərbaycan'), 2281),\n",
       " (('nəfərkəndin', 'əhalisi', 'yaşayır'), 2256),\n",
       " (('əhalisi', 'yaşayır', 'ailə'), 2254),\n",
       " (('görə', 'kənddə', 'nəfərkəndin'), 2245),\n",
       " (('kənddə', 'nəfərkəndin', 'əhalisi'), 2245),\n",
       " (('yaşayır', 'ailə', 'istinadlar'), 2196),\n",
       " (('ailə', 'istinadlar', 'kateqoriya'), 2195),\n",
       " (('mənbə', 'xarici', 'keçidlər'), 2131),\n",
       " (('istinadlar', 'xarici', 'keçidlər'), 1988),\n",
       " (('növü', 'mənbə', 'xarici'), 1919),\n",
       " (('bitki', 'növü', 'istinadlar'), 1884),\n",
       " (('siyahısı', 'səhləbkimilərə', 'aid'), 1832),\n",
       " (('xarici', 'keçidlər', 'bulbofilium'), 1831)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = MarkovChain()\n",
    "m3.train3(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Quadgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('cinsinə', 'aid', 'bitki', 'növü'), 9935),\n",
       " (('fəsiləsinin', 'cinsinə', 'aid', 'bitki'), 9854),\n",
       " (('aid', 'bitki', 'növü', 'mənbə'), 6906),\n",
       " (('mənbə', 'fəsiləsinin', 'cinsinə', 'aid'), 5041),\n",
       " (('növü', 'mənbə', 'fəsiləsinin', 'cinsinə'), 4897),\n",
       " (('bitki', 'növü', 'mənbə', 'fəsiləsinin'), 4841),\n",
       " (('ərazisinə', 'daxil', 'olan', 'kənd'), 2396),\n",
       " (('şəhristanı', 'ərazisinə', 'daxil', 'olan'), 2395),\n",
       " (('daxil', 'olan', 'kənd', 'əhalisi'), 2344),\n",
       " (('olan', 'kənd', 'əhalisi', 'cı'), 2305),\n",
       " (('kənd', 'əhalisi', 'cı', 'il'), 2304),\n",
       " (('cı', 'il', 'məlumatına', 'görə'), 2297),\n",
       " (('əhalisi', 'cı', 'il', 'məlumatına'), 2296),\n",
       " (('il', 'məlumatına', 'görə', 'kənddə'), 2294),\n",
       " (('iranın', 'qərbi', 'azərbaycan', 'ostanının'), 2277),\n",
       " (('nəfərkəndin', 'əhalisi', 'yaşayır', 'ailə'), 2254),\n",
       " (('görə', 'kənddə', 'nəfərkəndin', 'əhalisi'), 2245),\n",
       " (('kənddə', 'nəfərkəndin', 'əhalisi', 'yaşayır'), 2240),\n",
       " (('məlumatına', 'görə', 'kənddə', 'nəfərkəndin'), 2227),\n",
       " (('əhalisi', 'yaşayır', 'ailə', 'istinadlar'), 2196),\n",
       " (('yaşayır', 'ailə', 'istinadlar', 'kateqoriya'), 2190),\n",
       " (('növü', 'mənbə', 'xarici', 'keçidlər'), 1919),\n",
       " (('aid', 'bitki', 'növü', 'istinadlar'), 1880),\n",
       " (('bitki', 'növü', 'mənbə', 'xarici'), 1860),\n",
       " (('xarici', 'keçidlər', 'bulbofilium', 'yoxlama'), 1831),\n",
       " (('keçidlər', 'bulbofilium', 'yoxlama', 'siyahısı'), 1831),\n",
       " (('bulbofilium', 'yoxlama', 'siyahısı', 'səhləbkimilərə'), 1831),\n",
       " (('yoxlama', 'siyahısı', 'səhləbkimilərə', 'aid'), 1831),\n",
       " (('siyahısı', 'səhləbkimilərə', 'aid', 'növlərin'), 1831),\n",
       " (('səhləbkimilərə', 'aid', 'növlərin', 'internet'), 1831)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4 = MarkovChain()\n",
    "m4.train4(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Fivegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('fəsiləsinin', 'cinsinə', 'aid', 'bitki', 'növü'), 9853),\n",
       " (('cinsinə', 'aid', 'bitki', 'növü', 'mənbə'), 6906),\n",
       " (('mənbə', 'fəsiləsinin', 'cinsinə', 'aid', 'bitki'), 4986),\n",
       " (('növü', 'mənbə', 'fəsiləsinin', 'cinsinə', 'aid'), 4897),\n",
       " (('bitki', 'növü', 'mənbə', 'fəsiləsinin', 'cinsinə'), 4841),\n",
       " (('aid', 'bitki', 'növü', 'mənbə', 'fəsiləsinin'), 4840),\n",
       " (('şəhristanı', 'ərazisinə', 'daxil', 'olan', 'kənd'), 2393),\n",
       " (('ərazisinə', 'daxil', 'olan', 'kənd', 'əhalisi'), 2344),\n",
       " (('daxil', 'olan', 'kənd', 'əhalisi', 'cı'), 2305),\n",
       " (('olan', 'kənd', 'əhalisi', 'cı', 'il'), 2303),\n",
       " (('əhalisi', 'cı', 'il', 'məlumatına', 'görə'), 2296),\n",
       " (('cı', 'il', 'məlumatına', 'görə', 'kənddə'), 2294),\n",
       " (('kənd', 'əhalisi', 'cı', 'il', 'məlumatına'), 2287),\n",
       " (('görə', 'kənddə', 'nəfərkəndin', 'əhalisi', 'yaşayır'), 2240),\n",
       " (('kənddə', 'nəfərkəndin', 'əhalisi', 'yaşayır', 'ailə'), 2238),\n",
       " (('il', 'məlumatına', 'görə', 'kənddə', 'nəfərkəndin'), 2227),\n",
       " (('məlumatına', 'görə', 'kənddə', 'nəfərkəndin', 'əhalisi'), 2227),\n",
       " (('nəfərkəndin', 'əhalisi', 'yaşayır', 'ailə', 'istinadlar'), 2196),\n",
       " (('əhalisi', 'yaşayır', 'ailə', 'istinadlar', 'kateqoriya'), 2190),\n",
       " (('cinsinə', 'aid', 'bitki', 'növü', 'istinadlar'), 1880),\n",
       " (('aid', 'bitki', 'növü', 'mənbə', 'xarici'), 1860),\n",
       " (('bitki', 'növü', 'mənbə', 'xarici', 'keçidlər'), 1860),\n",
       " (('xarici', 'keçidlər', 'bulbofilium', 'yoxlama', 'siyahısı'), 1831),\n",
       " (('keçidlər', 'bulbofilium', 'yoxlama', 'siyahısı', 'səhləbkimilərə'), 1831),\n",
       " (('bulbofilium', 'yoxlama', 'siyahısı', 'səhləbkimilərə', 'aid'), 1831),\n",
       " (('yoxlama', 'siyahısı', 'səhləbkimilərə', 'aid', 'növlərin'), 1831),\n",
       " (('siyahısı', 'səhləbkimilərə', 'aid', 'növlərin', 'internet'), 1831),\n",
       " (('səhləbkimilərə', 'aid', 'növlərin', 'internet', 'foto'), 1831),\n",
       " (('aid', 'növlərin', 'internet', 'foto', 'ensiklopediyası'), 1825),\n",
       " (('növlərin', 'internet', 'foto', 'ensiklopediyası', 'fəsiləsinin'), 1813)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = MarkovChain()\n",
    "m5.train5(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import everygrams\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vocab = padded_everygram_pipeline(5, data_new)\n",
    "sent_tokenize = lambda x: regex.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "\n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(data_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, padded_sents = padded_everygram_pipeline(5, tokenized_text)\n",
    "mle = MLE(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mle.pickle']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(m2, 'bigrams.pickle')\n",
    "joblib.dump(m3, 'trigrams.pickle')\n",
    "joblib.dump(m4, 'quadgrams.pickle')\n",
    "joblib.dump(m5, 'fivegrams.pickle')\n",
    "joblib.dump(mle, 'mle.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = joblib.load('bigrams.pickle')\n",
    "m3 = joblib.load('trigrams.pickle')\n",
    "m4 = joblib.load('quadgrams.pickle')\n",
    "m5 = joblib.load('fivegrams.pickle')\n",
    "mle = joblib.load('mle.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "əhali\n",
      "Next word: yaşayır \n",
      "Probability: 0.1881720430107527\n",
      "\n",
      "List of unique words coming after əhali :\n",
      " ['yaşayır', 'iqtisadiyyatı', 'tərəfindən', 'rusiya', 'ilə', 'illərə', 'məlumatı', 'arasında', 'siyahıyaalınmasına', 'siyahıyaalmasının', 'əhalisi', 'sayı', 'yaşamaqdadır', 'kürdlərdən', 'əhalinin', 'rayonları', 'siyahıyaalmasına', 'kəndi', 'mövcuddur', 'cənubi', 'əsasən', 'tanınmışları', 'yaşamır', 'məskunlaşmışdır', 'dil', 'sayımına', 'qurtuluşu', 'muxtar', 'əhali', 'bölgə', 'şəkilmilli', 'dublin', 'sahə', 'sayıiləhali', 'sayına', 'ci', 'saymasına', 'məlumatları', 'sıxlığı', 'mahalın', 'siyahıya', 'sıxlığına', 'vilayət', 'etnik', 'sayının', 'statusaqtau', 'qubernatorluq', 'səh', 'siyahıalmasına', 'əhvaz', 'kotonu', 'xülasə', 'illər', 'kənd', 'geniş', 'kateqoriya', 'iqtisadiyyat', 'il', 'qardaşlaşmış', 'istinadlar', 'cı', 'islam', 'coğrafiyası', 'tarixi', 'milli', 'yaşamışdır', 'dinamika', 'bunu', 'mərkəzləri', 'bu', 'siyahıyaalmaya', 'საქართველოს', 'nəfərə', 'ərazi', 'km', 'cədvəlini', 'ilin', 'öz', 'şərabçılıq']\n",
      "\n",
      "Common words:\n",
      " [('yaşayır', 70), ('siyahıyaalmaya', 70), ('საქართველოს', 70), ('əhali', 11), ('ci', 10), ('iqtisadiyyat', 10), ('əhalisi', 7), ('siyahıyaalmasının', 6), ('milli', 6), ('arasında', 5)]\n"
     ]
    }
   ],
   "source": [
    "inp2_1 = input()\n",
    "inp2 = inp2_1.split(\" \")\n",
    "next_word_bi = m2.next(inp2[len(inp2)-1])\n",
    "next_word_bi_prob = mle.score(next_word_bi[0], inp2_1.split())\n",
    "print(\"Next word:\", next_word_bi[0], \"\\nProbability:\", next_word_bi_prob)\n",
    "print(\"\\nList of unique words coming after\",inp2[len(inp2)-1], \":\\n\", next_word_bi[1])\n",
    "print(\"\\nCommon words:\\n\", next_word_bi[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "əhali yaşayır\n",
      "Next word: azərbaycan \n",
      "Probability: 0.8714285714285714\n",
      "\n",
      "List of unique words coming after əhali əhali :\n",
      " ['iran', 'xəbərin', 'qax', 'azərbaycan', 'kateqoriya', 'əhalisi', 'əsasən', 'mənbə', 'территориальный']\n",
      "\n",
      "Common words: \n",
      " [('azərbaycan', 61), ('территориальный', 2), ('iran', 1), ('xəbərin', 1), ('qax', 1), ('kateqoriya', 1), ('əhalisi', 1), ('əsasən', 1), ('mənbə', 1)]\n"
     ]
    }
   ],
   "source": [
    "inp3_1 = input()\n",
    "inp3 = inp3_1.split(\" \")\n",
    "next_word_tri = m3.next(inp3[len(inp3)-2], inp3[len(inp3)-1])\n",
    "next_word_tri_prob = mle.score(next_word_tri[0], inp3_1.split())\n",
    "print(\"Next word:\", next_word_tri[0], \"\\nProbability:\", next_word_tri_prob)\n",
    "print(\"\\nList of unique words coming after\",inp3[len(inp3)-2], inp3[len(inp2)-1], \":\\n\", next_word_tri[1])\n",
    "print(\"\\nCommon words: \\n\", next_word_tri[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Quadgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "əhali yaşayır azərbaycan\n",
      "Next word:  respublikası \n",
      "Probability:  0.9836065573770492\n",
      "\n",
      "List of unique words coming after əhali yaşayır azərbaycan :\n",
      " ['respublikası', 'respublikasının']\n",
      "\n",
      "Common words:\n",
      " [('respublikası', 60), ('respublikasının', 1)]\n"
     ]
    }
   ],
   "source": [
    "inp4_1 = input()\n",
    "inp4 = inp4_1.split(\" \")\n",
    "next_word_quad = m4.next(inp4[len(inp4)-3], inp4[len(inp4)-2], inp4[len(inp4)-1])\n",
    "next_word_quad_prob = mle.score(next_word_quad[0], inp4_1.split())\n",
    "print(\"Next word: \", next_word_quad[0], \"\\nProbability: \", next_word_quad_prob)\n",
    "print(\"\\nList of unique words coming after\",inp4[len(inp4)-3], inp4[len(inp4)-2], inp4[len(inp4)-1], \":\\n\", next_word_quad[1])\n",
    "print(\"\\nCommon words:\\n\", next_word_quad[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Fivegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "əhali yaşayır azərbaycan respublikası\n",
      "Next word: əhalisinin \n",
      "Probability: 1.0\n",
      "\n",
      "List of unique words coming after əhali yaşayır azərbaycan respublikası :\n",
      " ['əhalisinin']\n",
      "\n",
      "Common words:\n",
      " [('əhalisinin', 60)]\n"
     ]
    }
   ],
   "source": [
    "inp5_1 = input()\n",
    "inp5 = inp5_1.split(\" \")\n",
    "next_word_five =  m5.next(inp5[len(inp5)-4], inp5[len(inp5)-3], inp5[len(inp5)-2], inp5[len(inp5)-1])\n",
    "next_word_five_prob = mle.score(next_word_five[0], inp5_1.split())\n",
    "print(\"Next word:\", next_word_five[0], \"\\nProbability:\", next_word_five_prob)\n",
    "print(\"\\nList of unique words coming after\", inp5[len(inp5)-4], inp5[len(inp5)-3], inp5[len(inp5)-2], inp5[len(inp5)-1], \":\\n\", next_word_five[1])\n",
    "print(\"\\nCommon words:\\n\", next_word_five[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"clean_wiki.txt\")\n",
    "\n",
    "text = train_data.to_string()\n",
    "\n",
    "# preprocess the text\n",
    "data_new = text_cleaner(text)\n",
    "\n",
    "from math import floor\n",
    "\n",
    "def get_training_and_testing_sets(file_list):\n",
    "    split = 0.95\n",
    "    split_index = floor(len(file_list) * split)\n",
    "    training = file_list[:split_index]\n",
    "    testing = file_list[split_index:]\n",
    "    return training, testing\n",
    "\n",
    "training, testing = get_training_and_testing_sets(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8774732\n",
      "461828\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "def text_cleaner(text):\n",
    "    # lower case text\n",
    "    newString = text.lower()\n",
    "    # adding space in place of punctuation between two words e.g: \"...redaktə edilib.Bu\", so it can be split later.\n",
    "    newString = regex.sub((r\"(?<=\\w)(\\W)(?=\\w)\"), ' ', newString)\n",
    "    # remove punctuations\n",
    "    newString = regex.sub((r\"[^\\A\\p{L}+\\z ]\"), '', newString) # matches unicode characters \n",
    "    # remove short words x_X\n",
    "    long_words = []\n",
    "    for i in newString.split():\n",
    "        if len(i) >= 3:\n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import nltk\n",
    "from nltk import SimpleGoodTuringProbDist\n",
    "from math import log\n",
    "\n",
    "class MarkovChain:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.memory = {}\n",
    "\n",
    "    def _learn_key(self, *key, value):\n",
    "        if key not in self.memory:\n",
    "            self.memory[key] = []\n",
    "\n",
    "        self.memory[key].append(value)\n",
    "        \n",
    "    def _learn_key1(self, *key):\n",
    "        if key not in self.memory:\n",
    "            self.memory[key] = []\n",
    "\n",
    "        self.memory[key].append(key)\n",
    "\n",
    "    def train1(self, text):\n",
    "        \n",
    "        tokens = text.split(\" \")\n",
    "        unigrams = [(tokens[i]) for i in range(0, len(tokens))]\n",
    "        combo_count = Counter(unigrams)\n",
    "        for unigram in unigrams:\n",
    "            self._learn_key1(unigram[0])\n",
    "        return combo_count.most_common(20)\n",
    "    def train2(self, text):\n",
    "        \n",
    "        tokens = text.split(\" \")\n",
    "        bigrams = [(tokens[i], tokens[i + 1]) for i in range(0, len(tokens) - 1)]\n",
    "        combo_count = Counter(bigrams)\n",
    "        for bigram in bigrams:\n",
    "            self._learn_key(bigram[0], value = bigram[1])\n",
    "        return combo_count.most_common(20)\n",
    "    \n",
    "    def train3(self, text):\n",
    "        tokens = text.split(\" \")\n",
    "        trigrams = [(tokens[i], tokens[i + 1], tokens[i + 2]) for i in range(0, len(tokens) - 2)]\n",
    "        tri_count = Counter(trigrams)\n",
    "        # pprint(trigrams)\n",
    "        for trigram in trigrams:\n",
    "            self._learn_key(trigram[0], trigram[1], value = trigram[2])\n",
    "        return tri_count.most_common(30)\n",
    "    def train4(self, text):\n",
    "        tokens = text.split(\" \")\n",
    "        quadgrams = [(tokens[i], tokens[i + 1], tokens[i + 2], tokens[i + 3]) for i in range(0, len(tokens) - 3)]\n",
    "        quad_count = Counter(quadgrams)\n",
    "        # pprint(quadgrams)\n",
    "        for quadgram in quadgrams:\n",
    "            self._learn_key(quadgram[0], quadgram[1], quadgram[2], value = quadgram[3])\n",
    "        return quad_count.most_common(30)\n",
    "    \n",
    "    def train5(self, text):\n",
    "        tokens = text.split(\" \")\n",
    "        fivegrams = [(tokens[i], tokens[i + 1], tokens[i + 2], tokens[i + 3], tokens[i + 4]) for i in range(0, len(tokens) - 4)]\n",
    "        five_count = Counter(fivegrams)\n",
    "        # pprint(fivegrams)\n",
    "        for fivegram in fivegrams:\n",
    "            self._learn_key(fivegram[0], fivegram[1], fivegram[2],fivegram[3], value = fivegram[4])\n",
    "        return five_count.most_common(30)\n",
    "\n",
    "    def next(self, *current_state):\n",
    "        next_possible = self.memory.get(current_state)\n",
    "\n",
    "        if not next_possible:\n",
    "            next_possible = self.memory.keys()\n",
    "\n",
    "        cnt = Counter(next_possible) \n",
    "        \n",
    "#         next_possible = cnt.most_common(1)[0]\n",
    "        next_possible = cnt.most_common(1)[0][0]\n",
    "    \n",
    "        return next_possible\n",
    "    \n",
    "    def _unigram_prob_with_add1smoothing(self, text, word):\n",
    "        freq_1gram= nltk.FreqDist(text)\n",
    "        len_train= len(text)\n",
    "        vocab= len(set(text))\n",
    "        return (freq_1gram[word]+1)/(len_train+vocab)\n",
    "    \n",
    "    def _bigram_prob_with_add1smoothing(self,text,word1, word2):\n",
    "        tokens = text.split(\" \")\n",
    "        bigrams = [(tokens[i], tokens[i + 1]) for i in range(0, len(tokens) - 1)]\n",
    "        cfreq_2gram = nltk.ConditionalFreqDist(bigrams)\n",
    "        cprob_2gram = nltk.ConditionalProbDist(cfreq_2gram, nltk.MLEProbDist)\n",
    "        cprob_2gram_add1=float((((1+cfreq_2gram[word1][word2])/(len(cfreq_2gram)+sum(cfreq_2gram[word1].values())))))\n",
    "        return cprob_2gram_add1\n",
    "       \n",
    "    def _trigram_prob_with_add1smoothing(self,text,w1, w2, w3):\n",
    "        tokens = text.split(\" \")\n",
    "        trigrams = [(tokens[i], tokens[i + 1], tokens[i + 2]) for i in range(0, len(tokens) - 2)]\n",
    "        trigrams_as_bigrams=[]\n",
    "        trigrams_as_bigrams.extend([((t[0],t[1]), t[2]) for t in trigrams])\n",
    "        cfreq_3gram = nltk.ConditionalFreqDist(trigrams_as_bigrams)\n",
    "        cprob_3gram = nltk.ConditionalProbDist(cfreq_3gram, nltk.MLEProbDist)\n",
    "        cprob_3gram_add1=(((1+cfreq_3gram[(w1,w2)][w3])/(len(cfreq_3gram)+sum(cfreq_3gram[(w1,w2)].values()))))\n",
    "        return cprob_3gram_add1\n",
    "        \n",
    "    def _fourgram_prob_with_add1smoothing(self,text,w1, w2, w3,w4):\n",
    "        tokens = text.split(\" \")\n",
    "        fourgrams = [(tokens[i], tokens[i + 1], tokens[i + 2],tokens[i+3]) for i in range(0, len(tokens) - 3)]\n",
    "        fourgrams_as_trigrams=[]\n",
    "        fourgrams_as_trigrams.extend([((t[0],t[1],t[2]),t[3]) for t in fourgrams])\n",
    "        cfreq_4gram = nltk.ConditionalFreqDist(fourgrams_as_trigrams)\n",
    "        cprob_4gram = nltk.ConditionalProbDist(cfreq_4gram, nltk.MLEProbDist)\n",
    "        cprob_4gram_add1=(((1+cfreq_4gram[(w1,w2,w3)][w4])/(len(cfreq_4gram)+sum(cfreq_4gram[(w1,w2,w3)].values()))))\n",
    "        return cprob_4gram_add1\n",
    "    \n",
    "    def _fivegram_prob_with_add1smoothing(self,text,w1, w2, w3,w4,w5):\n",
    "        tokens = text.split(\" \")\n",
    "        fourgrams = [(tokens[i], tokens[i + 1], tokens[i + 2],tokens[i+3],tokens[i+4]) for i in range(0, len(tokens) - 4)]\n",
    "        fivegrams_as_fourgrams=[]\n",
    "        fivegrams_as_fourgrams.extend([((t[0],t[1],t[2],t[3]),t[4]) for t in fivegrams])\n",
    "        cfreq_5gram = nltk.ConditionalFreqDist(fivegrams_as_fourgrams)\n",
    "        cprob_5gram = nltk.ConditionalProbDist(cfreq_5gram, nltk.MLEProbDist)\n",
    "        cprob_5gram_add1=(((1+cfreq_5gram[(w1,w2,w3,w4)][w5])/(len(cfreq_5gram)+sum(cfreq_5gram[(w1,w2,w3,w4)].values()))))\n",
    "        return cprob_5gram_add1\n",
    "    \n",
    "    def _entropy(self,n, text):\n",
    "        e = 0.0\n",
    "#         text = [\"<s>\"] + text + [\"</s>\"]\n",
    "        for i in range(n - 1, len(text)):\n",
    "            context = text[i - n + 1:i]\n",
    "            token = text[i]\n",
    "            #print(str(context)+\"    \"+token)\n",
    "            e += self._logprob(text,token, context)\n",
    "        return e / float(len(text) - (n - 1))\n",
    "\n",
    "\n",
    "    def _logprob(self,text,word, context):\n",
    "        if len(context)==0:\n",
    "            p=self._unigram_prob_with_add1smoothing(text,word)\n",
    "        elif len(context)==1:\n",
    "            p=self._bigram_prob_with_add1smoothing(text,context[0], word)\n",
    "        elif len(context)==2:\n",
    "            p=self._trigram_prob_with_add1smoothing(text,context[0], context[1], word)\n",
    "        else:\n",
    "            p=self._fourgram_prob_with_add1smoothing(text,context[0], context[1],context[2],word)\n",
    "        return -p*log(p , 2)\n",
    "\n",
    "\n",
    "    def perplexity(self,n, text):\n",
    "          return pow(2.0, self._entropy(n, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kateqoriya', 56028),\n",
       " ('görə', 17280),\n",
       " ('aid', 14628),\n",
       " ('azərbaycan', 11717),\n",
       " ('növü', 11491),\n",
       " ('cinsinə', 11158),\n",
       " ('bitki', 10693),\n",
       " ('istinadlar', 10381),\n",
       " ('mənbə', 10224),\n",
       " ('fəsiləsinin', 10072),\n",
       " ('ildə', 8037),\n",
       " ('ölkələrinə', 6909),\n",
       " ('xarici', 6161),\n",
       " ('keçidlər', 5516),\n",
       " ('bax', 5464),\n",
       " ('kənd', 4761),\n",
       " ('əhalisi', 4513),\n",
       " ('olan', 4424),\n",
       " ('xal', 3700),\n",
       " ('həmçinin', 3684)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MarkovChain()\n",
    "m.train1(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.perplexity(1,testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('cinsinə', 'aid'), 11150),\n",
       " (('aid', 'bitki'), 10370),\n",
       " (('bitki', 'növü'), 9984),\n",
       " (('fəsiləsinin', 'cinsinə'), 9944),\n",
       " (('növü', 'mənbə'), 7755),\n",
       " (('ölkələrinə', 'görə'), 6806),\n",
       " (('istinadlar', 'kateqoriya'), 5816),\n",
       " (('kateqoriya', 'ölkələrinə'), 5593),\n",
       " (('xarici', 'keçidlər'), 5491),\n",
       " (('mənbə', 'fəsiləsinin'), 5041),\n",
       " (('həmçinin', 'bax'), 3480),\n",
       " (('azərbaycan', 'respublikasının'), 2328),\n",
       " (('kateqoriya', 'azərbaycan'), 2309),\n",
       " (('illərinə', 'görə'), 2166),\n",
       " (('mənbə', 'xarici'), 2132),\n",
       " (('daxil', 'olan'), 2007),\n",
       " (('növü', 'istinadlar'), 2002),\n",
       " (('müzakirə', 'redaktə'), 1922),\n",
       " (('bax', 'müzakirə'), 1920),\n",
       " (('azərbaycan', 'ostanının'), 1878)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.train2(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.perplexity(2,testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('aid', 'bitki', 'növü'), 9963),\n",
       " (('fəsiləsinin', 'cinsinə', 'aid'), 9944),\n",
       " (('cinsinə', 'aid', 'bitki'), 9936),\n",
       " (('bitki', 'növü', 'mənbə'), 6907),\n",
       " (('kateqoriya', 'ölkələrinə', 'görə'), 5531),\n",
       " (('mənbə', 'fəsiləsinin', 'cinsinə'), 5041),\n",
       " (('növü', 'mənbə', 'fəsiləsinin'), 4897),\n",
       " (('mənbə', 'xarici', 'keçidlər'), 2131),\n",
       " (('bax', 'müzakirə', 'redaktə'), 1920),\n",
       " (('növü', 'mənbə', 'xarici'), 1919),\n",
       " (('bitki', 'növü', 'istinadlar'), 1884),\n",
       " (('siyahısı', 'səhləbkimilərə', 'aid'), 1832),\n",
       " (('xarici', 'keçidlər', 'bulbofilium'), 1831),\n",
       " (('keçidlər', 'bulbofilium', 'yoxlama'), 1831),\n",
       " (('bulbofilium', 'yoxlama', 'siyahısı'), 1831),\n",
       " (('yoxlama', 'siyahısı', 'səhləbkimilərə'), 1831),\n",
       " (('səhləbkimilərə', 'aid', 'növlərin'), 1831),\n",
       " (('aid', 'növlərin', 'internet'), 1831),\n",
       " (('növlərin', 'internet', 'foto'), 1831),\n",
       " (('internet', 'foto', 'ensiklopediyası'), 1825),\n",
       " (('foto', 'ensiklopediyası', 'fəsiləsinin'), 1813),\n",
       " (('ensiklopediyası', 'fəsiləsinin', 'cinsinə'), 1813),\n",
       " (('istinadlar', 'xarici', 'keçidlər'), 1787),\n",
       " (('müzakirə', 'redaktə', 'tarixçə'), 1760),\n",
       " (('ərazisinə', 'daxil', 'olan'), 1679),\n",
       " (('daxil', 'olan', 'kənd'), 1677),\n",
       " (('şəhristanı', 'ərazisinə', 'daxil'), 1670),\n",
       " (('inzibati', 'ərazi', 'vahidində'), 1650),\n",
       " (('olan', 'kənd', 'əhalisi'), 1632),\n",
       " (('istinadlar', 'fəsiləsinin', 'cinsinə'), 1618)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.train3(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.perplexity(3,testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('cinsinə', 'aid', 'bitki', 'növü'), 9935),\n",
       " (('fəsiləsinin', 'cinsinə', 'aid', 'bitki'), 9854),\n",
       " (('aid', 'bitki', 'növü', 'mənbə'), 6906),\n",
       " (('mənbə', 'fəsiləsinin', 'cinsinə', 'aid'), 5041),\n",
       " (('növü', 'mənbə', 'fəsiləsinin', 'cinsinə'), 4897),\n",
       " (('bitki', 'növü', 'mənbə', 'fəsiləsinin'), 4841),\n",
       " (('növü', 'mənbə', 'xarici', 'keçidlər'), 1919),\n",
       " (('aid', 'bitki', 'növü', 'istinadlar'), 1880),\n",
       " (('bitki', 'növü', 'mənbə', 'xarici'), 1860),\n",
       " (('xarici', 'keçidlər', 'bulbofilium', 'yoxlama'), 1831),\n",
       " (('keçidlər', 'bulbofilium', 'yoxlama', 'siyahısı'), 1831),\n",
       " (('bulbofilium', 'yoxlama', 'siyahısı', 'səhləbkimilərə'), 1831),\n",
       " (('yoxlama', 'siyahısı', 'səhləbkimilərə', 'aid'), 1831),\n",
       " (('siyahısı', 'səhləbkimilərə', 'aid', 'növlərin'), 1831),\n",
       " (('səhləbkimilərə', 'aid', 'növlərin', 'internet'), 1831),\n",
       " (('aid', 'növlərin', 'internet', 'foto'), 1831),\n",
       " (('növlərin', 'internet', 'foto', 'ensiklopediyası'), 1825),\n",
       " (('internet', 'foto', 'ensiklopediyası', 'fəsiləsinin'), 1813),\n",
       " (('foto', 'ensiklopediyası', 'fəsiləsinin', 'cinsinə'), 1813),\n",
       " (('ensiklopediyası', 'fəsiləsinin', 'cinsinə', 'aid'), 1813),\n",
       " (('bax', 'müzakirə', 'redaktə', 'tarixçə'), 1758),\n",
       " (('mənbə', 'xarici', 'keçidlər', 'bulbofilium'), 1729),\n",
       " (('ərazisinə', 'daxil', 'olan', 'kənd'), 1672),\n",
       " (('şəhristanı', 'ərazisinə', 'daxil', 'olan'), 1670),\n",
       " (('daxil', 'olan', 'kənd', 'əhalisi'), 1632),\n",
       " (('istinadlar', 'fəsiləsinin', 'cinsinə', 'aid'), 1618),\n",
       " (('növü', 'istinadlar', 'fəsiləsinin', 'cinsinə'), 1593),\n",
       " (('bitki', 'növü', 'istinadlar', 'fəsiləsinin'), 1590),\n",
       " (('əhalisi', 'məlumatına', 'görə', 'kənddə'), 1582),\n",
       " (('kənd', 'əhalisi', 'məlumatına', 'görə'), 1576)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.train4(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.perplexity(4,testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('fəsiləsinin', 'cinsinə', 'aid', 'bitki', 'növü'), 9853),\n",
       " (('cinsinə', 'aid', 'bitki', 'növü', 'mənbə'), 6906),\n",
       " (('mənbə', 'fəsiləsinin', 'cinsinə', 'aid', 'bitki'), 4986),\n",
       " (('növü', 'mənbə', 'fəsiləsinin', 'cinsinə', 'aid'), 4897),\n",
       " (('bitki', 'növü', 'mənbə', 'fəsiləsinin', 'cinsinə'), 4841),\n",
       " (('aid', 'bitki', 'növü', 'mənbə', 'fəsiləsinin'), 4840),\n",
       " (('cinsinə', 'aid', 'bitki', 'növü', 'istinadlar'), 1880),\n",
       " (('aid', 'bitki', 'növü', 'mənbə', 'xarici'), 1860),\n",
       " (('bitki', 'növü', 'mənbə', 'xarici', 'keçidlər'), 1860),\n",
       " (('xarici', 'keçidlər', 'bulbofilium', 'yoxlama', 'siyahısı'), 1831),\n",
       " (('keçidlər', 'bulbofilium', 'yoxlama', 'siyahısı', 'səhləbkimilərə'), 1831),\n",
       " (('bulbofilium', 'yoxlama', 'siyahısı', 'səhləbkimilərə', 'aid'), 1831),\n",
       " (('yoxlama', 'siyahısı', 'səhləbkimilərə', 'aid', 'növlərin'), 1831),\n",
       " (('siyahısı', 'səhləbkimilərə', 'aid', 'növlərin', 'internet'), 1831),\n",
       " (('səhləbkimilərə', 'aid', 'növlərin', 'internet', 'foto'), 1831),\n",
       " (('aid', 'növlərin', 'internet', 'foto', 'ensiklopediyası'), 1825),\n",
       " (('növlərin', 'internet', 'foto', 'ensiklopediyası', 'fəsiləsinin'), 1813),\n",
       " (('internet', 'foto', 'ensiklopediyası', 'fəsiləsinin', 'cinsinə'), 1813),\n",
       " (('foto', 'ensiklopediyası', 'fəsiləsinin', 'cinsinə', 'aid'), 1813),\n",
       " (('ensiklopediyası', 'fəsiləsinin', 'cinsinə', 'aid', 'bitki'), 1813),\n",
       " (('mənbə', 'xarici', 'keçidlər', 'bulbofilium', 'yoxlama'), 1729),\n",
       " (('növü', 'mənbə', 'xarici', 'keçidlər', 'bulbofilium'), 1725),\n",
       " (('şəhristanı', 'ərazisinə', 'daxil', 'olan', 'kənd'), 1670),\n",
       " (('ərazisinə', 'daxil', 'olan', 'kənd', 'əhalisi'), 1632),\n",
       " (('istinadlar', 'fəsiləsinin', 'cinsinə', 'aid', 'bitki'), 1616),\n",
       " (('növü', 'istinadlar', 'fəsiləsinin', 'cinsinə', 'aid'), 1593),\n",
       " (('aid', 'bitki', 'növü', 'istinadlar', 'fəsiləsinin'), 1590),\n",
       " (('bitki', 'növü', 'istinadlar', 'fəsiləsinin', 'cinsinə'), 1590),\n",
       " (('kənd', 'əhalisi', 'məlumatına', 'görə', 'kənddə'), 1575),\n",
       " (('daxil', 'olan', 'kənd', 'əhalisi', 'məlumatına'), 1575)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.train5(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.perplexity(5,testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
